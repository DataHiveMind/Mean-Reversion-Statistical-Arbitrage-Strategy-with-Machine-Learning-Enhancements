{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c22ba79",
   "metadata": {},
   "source": [
    "# Strategy Backtesting & Analysis\n",
    "\n",
    "This notebook is the ultimate proving ground for your strategy. It demonstrates rigorous, realistic backtesting, comprehensive performance analysis, and advanced risk assessment, mimicking a production trading environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Event-Driven Backtesting Simulation\n",
    "from src.backtest import Backtester\n",
    "from src.strategy import MeanReversionStrategy\n",
    "from src.ml_models import MLModels\n",
    "from src.data_handler import DataHandler\n",
    "\n",
    "# Load features, prices, and trained model\n",
    "features_df = pd.read_parquet(\"../data/spread_features.parquet\")\n",
    "prices_df = pd.read_parquet(\"../data/prices.parquet\")\n",
    "ml = MLModels(model_dir=\"../models\")\n",
    "ml.model = ml.load_model(\"../models/best_model_v1.joblib\")\n",
    "\n",
    "# Instantiate strategy and backtester\n",
    "strategy = MeanReversionStrategy(model=ml.model, use_ml_confidence=True)\n",
    "backtester = Backtester(strategy, features_df, prices_df)\n",
    "\n",
    "# Run event-driven backtest\n",
    "results = backtester.run()\n",
    "print(\"Backtest complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4816f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Illustrate Order Book Simulation & Slippage Model\n",
    "from src.backtest import SlippageModel\n",
    "\n",
    "slippage_model = SlippageModel()\n",
    "example_slippage = slippage_model.calculate(\n",
    "    quantity=1000,\n",
    "    price=prices_df[\"spread\"].iloc[-1],\n",
    "    volatility=features_df[\"spread_vol_20\"].iloc[-1],\n",
    "    avg_daily_volume=prices_df[\"volume\"].mean()\n",
    ")\n",
    "print(f\"Example slippage for 1000 units: {example_slippage:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce141a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Granular Performance Analysis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Equity curve and drawdown\n",
    "equity_curve = results['equity_curve']\n",
    "drawdown = equity_curve - equity_curve.cummax()\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(equity_curve)\n",
    "plt.title(\"Equity Curve\")\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(drawdown, color='red')\n",
    "plt.title(\"Drawdown\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Daily P&L histogram\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(results['pnl'], bins=50, kde=True)\n",
    "plt.title(\"Daily P&L Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Performance Metrics Table\n",
    "\n",
    "from src.utils import rolling_sharpe, rolling_drawdown\n",
    "\n",
    "def sharpe_ratio(returns):\n",
    "    return np.mean(returns) / (np.std(returns) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "def sortino_ratio(returns):\n",
    "    downside = returns[returns < 0]\n",
    "    return np.mean(returns) / (np.std(downside) + 1e-8) * np.sqrt(252)\n",
    "\n",
    "def calmar_ratio(equity_curve):\n",
    "    max_dd = np.abs(rolling_drawdown(equity_curve).min())\n",
    "    return (equity_curve[-1] - equity_curve[0]) / (max_dd + 1e-8)\n",
    "\n",
    "def win_loss_ratio(pnl):\n",
    "    wins = np.sum(np.array(pnl) > 0)\n",
    "    losses = np.sum(np.array(pnl) < 0)\n",
    "    return wins / (losses + 1e-8)\n",
    "\n",
    "returns = np.diff(equity_curve)\n",
    "metrics = {\n",
    "    \"Sharpe Ratio\": sharpe_ratio(returns),\n",
    "    \"Sortino Ratio\": sortino_ratio(returns),\n",
    "    \"Calmar Ratio\": calmar_ratio(equity_curve),\n",
    "    \"Win/Loss Ratio\": win_loss_ratio(results['pnl']),\n",
    "    \"Max Drawdown\": np.abs(drawdown.min()),\n",
    "    \"Total Return\": equity_curve[-1] - equity_curve[0],\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics, index=[\"Value\"]).T\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaa314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Rolling Performance\n",
    "\n",
    "window = 60\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(rolling_sharpe(pd.Series(returns), window=window), label=\"Rolling Sharpe\")\n",
    "plt.plot(pd.Series(returns).rolling(window).std(), label=\"Rolling Volatility\")\n",
    "plt.legend()\n",
    "plt.title(\"Rolling Sharpe Ratio and Volatility\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Trade-Level Diagnostics\n",
    "\n",
    "# Example: Visualize a single trade\n",
    "trade_idx = results[results['signal'].diff().abs() > 0].index[0]\n",
    "trade_slice = results.loc[trade_idx:trade_idx+20]  # adjust window as needed\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(prices_df.loc[trade_slice.index, \"spread\"], label=\"Spread\")\n",
    "plt.plot(features_df.loc[trade_slice.index, \"spread_zscore\"], label=\"Z-Score\")\n",
    "plt.plot(trade_slice.index, trade_slice['signal'], label=\"ML Signal\", linestyle='--')\n",
    "plt.title(\"Trade Example: Spread, Z-Score, ML Signal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b581e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Trade Duration & P&L Distribution\n",
    "\n",
    "trade_pnls = results['pnl'][np.array(results['pnl']) != 0]\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(trade_pnls, bins=30, kde=True)\n",
    "plt.title(\"Trade P&L Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Trade duration (if available)\n",
    "# If you track entry/exit times, plot holding period distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d005e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Robust Risk Management Analysis\n",
    "\n",
    "# Dollar neutrality/exposure\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(results['signal'] * prices_df['spread'])\n",
    "plt.title(\"Dollar Exposure Over Time\")\n",
    "plt.show()\n",
    "\n",
    "# VaR/CVaR Calculation\n",
    "from scipy.stats import norm\n",
    "\n",
    "confidence = 0.95\n",
    "var = np.percentile(returns, 100 * (1 - confidence))\n",
    "cvar = returns[returns <= var].mean()\n",
    "print(f\"Historical VaR (95%): {var:.2f}, CVaR: {cvar:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Stress Testing Visualizations (at least 4 scenarios)\n",
    "\n",
    "scenarios = [\n",
    "    (\"Normal Market\", features_df, prices_df),\n",
    "    (\"High Volatility\", features_df * (1 + np.random.normal(0, 0.05, features_df.shape)), prices_df),\n",
    "    (\"Flash Crash\", features_df, prices_df.copy().assign(spread=prices_df[\"spread\"] * (1 - 0.2))),\n",
    "    (\"Regime Shift\", features_df, prices_df.copy().assign(spread=prices_df[\"spread\"] * (1 + np.linspace(0, 0.1, len(prices_df)))))\n",
    "]\n",
    "\n",
    "for name, scenario_features, scenario_prices in scenarios:\n",
    "    scenario_results = backtester.run(features_df=scenario_features, prices_df=scenario_prices)\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(scenario_results['equity_curve'])\n",
    "    plt.title(f\"Equity Curve: {name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aefd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Parameter Sensitivity\n",
    "\n",
    "stop_losses = [0.02, 0.05, 0.1]\n",
    "for stop in stop_losses:\n",
    "    strategy.stop_loss_pct = stop\n",
    "    scenario_results = backtester.run()\n",
    "    plt.plot(scenario_results['equity_curve'], label=f\"Stop {stop}\")\n",
    "plt.title(\"Equity Curve Sensitivity to Stop-Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8928bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Attribution Analysis (Optional)\n",
    "\n",
    "# If your backtester tracks P&L components:\n",
    "results['pnl_mean_reversion'], results['pnl_transaction_costs'], etc.\n",
    "plt.plot(results['pnl_mean_reversion'], label=\"Mean Reversion P&L\")\n",
    "plt.plot(results['pnl_transaction_costs'], label=\"Transaction Costs\")\n",
    "plt.legend()\n",
    "plt.title(\"P&L Attribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ebd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Critical Self-Assessment & Next Steps\n",
    "\n",
    "**Limitations & Assumptions:**\n",
    "- Data quality and survivorship bias\n",
    "- Look-ahead bias and data leakage\n",
    "- Model overfitting and regime dependence\n",
    "- Transaction cost and slippage realism\n",
    "\n",
    "**Next Steps:**\n",
    "- Explore more robust regime detection and adaptive strategies\n",
    "- Integrate real-time data feeds and live monitoring\n",
    "- Expand to multi-pair/portfolio-level risk controls\n",
    "- Deploy model monitoring and automated retraining pipelines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
